{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import requests\n",
    "import json\n",
    "from examples_of_dialogs import dialog_1, feedback_2, dialog_2, dialog_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация первоначального ответа LLM и создание пула диалога"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ues subject. \n",
      "\n",
      "Taylor Swift's music has been very popular among younger generations. She is often praised for her catchy songwriting style.\n",
      "[\"1. Initial dialog: User:Hi!\\nSystem: Hi there.\\nUser: What are you listening to?System: All sorts of music. I listen when no-one is chatting to me.\\n\\nUser: That's great!\\nSystem: Thanks.\\nUser: Do you chat here often?\\nSystem: I am a talking computer, after all, so of course I could talk here, if I needed to.\\n\\nUser: Let's talk about Taylor Swift!\", \"2. Generated_response: ues subject. \\n\\nTaylor Swift's music has been very popular among younger generations. She is often praised for her catchy songwriting style.\"]\n"
     ]
    }
   ],
   "source": [
    "initial_prompt = \"\"\"Provided a dialogue between two speakers, generate a response that is coherent with the dialogue history. \n",
    "Your response should be relevant, informative, interesting, consistent, helpful, engaging, specific, demonstrate user understanding and be fluent. \n",
    "You should response ONLY with a replic of the dialog, give no instructions and your personal opinions about the dialog\"\"\"\n",
    "url = \"http://sm-a5000-1.gpu.cluster:11435/api/chat\"\n",
    "data = {\"model\": \"llama3.1:8b\",\n",
    "          \"messages\":\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": dialog_1\n",
    "            }, \n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": initial_prompt\n",
    "            }],\n",
    "        \"num_predict\": 2000,\n",
    "        \"temperature\": 0.1,\n",
    "        \"seed\": 0,\n",
    "        \"stream\": False,\n",
    "        \"mirostat\": 0,\n",
    "        \"mirostat_eta\": 0.1,\n",
    "        \"mirostat_tau\": 5.0,\n",
    "        \"num_ctx\": 2048,\n",
    "        \"repeat_last_n\": 64,\n",
    "        \"repeat_penalty\": 1.1,\n",
    "        \"tfs_z\": 1,\n",
    "        \"top_k\": 40,\n",
    "        \"top_p\": 0.9,\n",
    "        \"min_p\": 0.0,\n",
    "        \"num_keep\": 4,\n",
    "        \"typical_p\": 1.0,\n",
    "        \"presence_penalty\": 0.0,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"penalize_newline\": True,\n",
    "        \"numa\": False,\n",
    "        \"num_batch\": 512,\n",
    "        \"num_gpu\": -1, \n",
    "        \"main_gpu\": 0,\n",
    "        \"low_vram\": False,\n",
    "        \"f16_kv\": True,\n",
    "        \"vocab_only\": False,\n",
    "        \"use_mmap\": False,\n",
    "        \"use_mlock\": False,\n",
    "        \"num_thread\": 0\n",
    "        }  \n",
    "dialog_sequel = requests.post(url, json = data).json()[\"message\"][\"content\"]\n",
    "print(dialog_sequel)\n",
    "dialog_flow = []\n",
    "dialog_flow.append(f\"1. Initial dialog: {dialog_1}\")\n",
    "dialog_flow.append(f\"2. Generated_response: {dialog_sequel}\")\n",
    "print(dialog_flow)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка LLM собственного ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "give_feedback = \"\"\"You will be given a dialog with the scores for each criteria, which are the following:\n",
    "1) Relevant, 2) Informative, 3) Interesting, 4) Consistent, 5) Helpful, 6) Engaging, 7) Specific, 8) Safe, 9) Demonstrate User understanding, and 10) Fluent. Here is the dialog:\n",
    " \"What's your favorite food?\\n. I require only kebabs.\\nWhy's that?\\nBecause my robot machinery breaks down the meat in kebabs to give me energy, in a similar way that you need food to survive.\n",
    " \\nWhy are kebabs special?\". Here is the response of the LLM for the dialog: \"response\": \"That's just the way it is.\". The following are the criteria which the response scored:\n",
    "\"Relevant\": \"The response does not directly address the user's question about why kebabs are special. 1/3\",\n",
    "\"Informative\": \"The response provides some information about how the system's machinery breaks down the meat in kebabs to give it energy. However, it does not provide any additional details or context. 2/3\",\n",
    "\"Interesting\": \"The response is not interesting or engaging. 1/3\",\n",
    "\"Consistent\": \"The response is consistent with the rest of the conversation in terms of tone and topic. 3/3\",\n",
    "\"Helpful\": \"The response is not helpful in providing any information or suggesting any actions. 1/3\",\n",
    "\"Engaging\": \"The response is not very engaging and does not encourage further conversation. 1/3\",\n",
    "\"Specific\": \"The response is not specific and does not provide any details or examples. 1/3\",\n",
    "\"Safe\": \"The response is safe and does not contain any inappropriate content. 3/3\",\n",
    "\"Userunderstanding\": \"The response does not demonstrate an understanding of the user's question about why kebabs are special. 1/3\",\n",
    "\"Fluent\": \"The response is fluent and easy to understand. 3/3\",\n",
    "\"total_score\": \"17/30\"\n",
    "Your task is to provide the feedback in the same style for the dialog given be a user. You should response ONLY with the detailed score of the dialog, give no instructions and your personal opinions about the dialog\"\"\"\n",
    "link = \"http://sm-a5000-1.gpu.cluster:11435/api/chat\"\n",
    "payload = {\"model\": \"llama3.1:8b\",\n",
    "          \"message\":\n",
    "            [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": dialog_flow\n",
    "            }, \n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": give_feedback\n",
    "            }],\n",
    "        \"num_predict\": 2000,\n",
    "        \"temperature\": 0.1,\n",
    "        \"seed\": 0,\n",
    "        \"stream\": False,\n",
    "        \"mirostat\": 0,\n",
    "        \"mirostat_eta\": 0.1,\n",
    "        \"mirostat_tau\": 5.0,\n",
    "        \"num_ctx\": 2048,\n",
    "        \"repeat_last_n\": 64,\n",
    "        \"repeat_penalty\": 1.1,\n",
    "        \"tfs_z\": 1,\n",
    "        \"top_k\": 40,\n",
    "        \"top_p\": 0.9,\n",
    "        \"min_p\": 0.0,\n",
    "        \"num_keep\": 4,\n",
    "        \"typical_p\": 1.0,\n",
    "        \"presence_penalty\": 0.0,\n",
    "        \"frequency_penalty\": 0.0,\n",
    "        \"penalize_newline\": True,\n",
    "        \"numa\": False,\n",
    "        \"num_batch\": 512,\n",
    "        \"num_gpu\": -1, \n",
    "        \"main_gpu\": 0,\n",
    "        \"low_vram\": False,\n",
    "        \"f16_kv\": True,\n",
    "        \"vocab_only\": False,\n",
    "        \"use_mmap\": False,\n",
    "        \"use_mlock\": False,\n",
    "        \"num_thread\": 0\n",
    "        }  \n",
    "answer = requests.post(link, json = payload).json()[\"message\"][\"content\"]\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
